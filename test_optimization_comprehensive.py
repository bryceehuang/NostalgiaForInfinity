"""
ç»¼åˆä¼˜åŒ–æµ‹è¯•å¥—ä»¶
æµ‹è¯•çº¯æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬çš„å„é¡¹åŠŸèƒ½å’Œæ€§èƒ½æŒ‡æ ‡
"""

import pytest
import pandas as pd
import numpy as np
import time
import gc
import psutil
import logging
from datetime import datetime, timedelta
from unittest.mock import Mock, patch

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TestPerformanceOptimization:
    """çº¯æ€§èƒ½ä¼˜åŒ–æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def sample_data(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        np.random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡å¤
        dates = pd.date_range(start='2023-01-01', periods=10000, freq='5min')
        
        data = {
            'open': 100 + np.random.randn(10000).cumsum() * 0.1,
            'high': 101 + np.random.randn(10000).cumsum() * 0.1,
            'low': 99 + np.random.randn(10000).cumsum() * 0.1,
            'close': 100 + np.random.randn(10000).cumsum() * 0.1,
            'volume': np.random.randint(1000, 10000, 10000),
            'date': dates
        }
        
        return pd.DataFrame(data)
    
    @pytest.fixture
    def mock_original_strategy(self):
        """åˆ›å»ºæ¨¡æ‹ŸåŸå§‹ç­–ç•¥"""
        strategy = Mock()
        strategy.stoploss = -0.50
        
        def mock_populate_indicators(dataframe, metadata):
            # æ¨¡æ‹Ÿé‡è®¡ç®—è´Ÿè½½
            for i in range(50):
                dataframe[f'indicator_{i}'] = dataframe['close'].rolling(i+1).mean()
            return dataframe
        
        def mock_populate_entry_trend(dataframe, metadata):
            dataframe['enter_long'] = (dataframe['close'] > dataframe['close'].rolling(20).mean()).astype(int)
            dataframe['enter_short'] = (dataframe['close'] < dataframe['close'].rolling(20).mean()).astype(int)
            return dataframe
        
        def mock_populate_exit_trend(dataframe, metadata):
            dataframe['exit_long'] = (dataframe['close'] < dataframe['close'].rolling(20).mean()).astype(int)
            dataframe['exit_short'] = (dataframe['close'] > dataframe['close'].rolling(20).mean()).astype(int)
            return dataframe
        
        def mock_custom_stoploss(pair, trade, current_time, current_rate, current_profit, **kwargs):
            return -0.50
        
        strategy.populate_indicators = mock_populate_indicators
        strategy.populate_entry_trend = mock_populate_entry_trend
        strategy.populate_exit_trend = mock_populate_exit_trend
        strategy.custom_stoploss = mock_custom_stoploss
        
        return strategy
    
    @pytest.fixture
    def optimized_strategy(self, mock_original_strategy):
        """åˆ›å»ºä¼˜åŒ–ç­–ç•¥å®ä¾‹"""
        try:
            from NostalgiaForInfinityX6_CC_performance_only import create_performance_wrapper
            return create_performance_wrapper(mock_original_strategy)
        except ImportError as e:
            logger.error(f"å¯¼å…¥ä¼˜åŒ–æ¨¡å—å¤±è´¥: {e}")
            pytest.skip("ä¼˜åŒ–æ¨¡å—ä¸å¯ç”¨")
    
    def test_basic_functionality(self, optimized_strategy, sample_data):
        """æµ‹è¯•åŸºæœ¬åŠŸèƒ½æ˜¯å¦æ­£å¸¸"""
        logger.info("æµ‹è¯•åŸºæœ¬åŠŸèƒ½...")
        
        metadata = {'pair': 'BTC/USDT'}
        
        # æµ‹è¯•æŒ‡æ ‡è®¡ç®—
        result = optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
        assert result is not None, "æŒ‡æ ‡è®¡ç®—å¤±è´¥"
        assert len(result) == len(sample_data), "æ•°æ®é•¿åº¦ä¸ä¸€è‡´"
        assert 'indicator_0' in result.columns, "æŒ‡æ ‡æœªæ­£ç¡®è®¡ç®—"
        
        logger.info("âœ… åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    def test_caching_effectiveness(self, optimized_strategy, sample_data):
        """æµ‹è¯•ç¼“å­˜æ•ˆæœ"""
        logger.info("æµ‹è¯•ç¼“å­˜æ•ˆæœ...")
        
        metadata = {'pair': 'BTC/USDT'}
        
        # ç¬¬ä¸€æ¬¡è®¡ç®—ï¼ˆåº”è¯¥ç¼“å­˜æœªå‘½ä¸­ï¼‰
        start_time = time.time()
        result1 = optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
        first_time = time.time() - start_time
        
        # ç¬¬äºŒæ¬¡è®¡ç®—ï¼ˆåº”è¯¥ç¼“å­˜å‘½ä¸­ï¼‰
        start_time = time.time()
        result2 = optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
        second_time = time.time() - start_time
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        pd.testing.assert_frame_equal(result1, result2)
        
        # éªŒè¯æ€§èƒ½æå‡
        assert second_time < first_time * 0.5, f"ç¼“å­˜æ•ˆæœä¸ä½³: ç¬¬ä¸€æ¬¡{first_time:.3f}s, ç¬¬äºŒæ¬¡{second_time:.3f}s"
        
        # æ£€æŸ¥ç¼“å­˜ç»Ÿè®¡
        stats = optimized_strategy.get_performance_stats()
        assert stats['cache_performance']['hits'] > 0, "ç¼“å­˜æœªå‘½ä¸­"
        
        logger.info(f"âœ… ç¼“å­˜æ•ˆæœæµ‹è¯•é€šè¿‡ - ç¬¬ä¸€æ¬¡: {first_time:.3f}s, ç¬¬äºŒæ¬¡: {second_time:.3f}s")
    
    def test_memory_optimization(self, optimized_strategy, sample_data):
        """æµ‹è¯•å†…å­˜ä¼˜åŒ–æ•ˆæœ"""
        logger.info("æµ‹è¯•å†…å­˜ä¼˜åŒ–æ•ˆæœ...")
        
        metadata = {'pair': 'BTC/USDT'}
        
        # è®°å½•å†…å­˜ä½¿ç”¨
        process = psutil.Process()
        memory_before = process.memory_info().rss / (1024**2)  # MB
        
        # æ‰§è¡Œä¼˜åŒ–è®¡ç®—
        result = optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
        
        memory_after = process.memory_info().rss / (1024**2)  # MB
        memory_increase = memory_after - memory_before
        
        # éªŒè¯å†…å­˜ä½¿ç”¨åˆç†
        assert memory_increase < 100, f"å†…å­˜ä½¿ç”¨å¢åŠ è¿‡å¤š: {memory_increase:.1f}MB"
        
        logger.info(f"âœ… å†…å­˜ä¼˜åŒ–æµ‹è¯•é€šè¿‡ - å†…å­˜å¢åŠ : {memory_increase:.1f}MB")
    
    def test_entry_exit_signals(self, optimized_strategy, sample_data):
        """æµ‹è¯•å…¥åœºå‡ºåœºä¿¡å·"""
        logger.info("æµ‹è¯•å…¥åœºå‡ºåœºä¿¡å·...")
        
        metadata = {'pair': 'BTC/USDT'}
        
        # å…ˆè®¡ç®—æŒ‡æ ‡
        dataframe = optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
        
        # æµ‹è¯•å…¥åœºä¿¡å·
        entry_df = optimized_strategy.populate_entry_trend_with_cache(dataframe.copy(), metadata)
        assert 'enter_long' in entry_df.columns, "å…¥åœºä¿¡å·æœªç”Ÿæˆ"
        assert 'enter_short' in entry_df.columns, "å…¥åœºä¿¡å·æœªç”Ÿæˆ"
        assert entry_df['enter_long'].dtype == int, "å…¥åœºä¿¡å·ç±»å‹é”™è¯¯"
        
        # æµ‹è¯•å‡ºåœºä¿¡å·
        exit_df = optimized_strategy.populate_exit_trend_with_cache(dataframe.copy(), metadata)
        assert 'exit_long' in exit_df.columns, "å‡ºåœºä¿¡å·æœªç”Ÿæˆ"
        assert 'exit_short' in exit_df.columns, "å‡ºåœºä¿¡å·æœªç”Ÿæˆ"
        assert exit_df['exit_long'].dtype == int, "å‡ºåœºä¿¡å·ç±»å‹é”™è¯¯"
        
        logger.info("âœ… å…¥åœºå‡ºåœºä¿¡å·æµ‹è¯•é€šè¿‡")
    
    def test_custom_stoploss(self, optimized_strategy):
        """æµ‹è¯•è‡ªå®šä¹‰æ­¢æŸ"""
        logger.info("æµ‹è¯•è‡ªå®šä¹‰æ­¢æŸ...")
        
        # åˆ›å»ºæ¨¡æ‹Ÿäº¤æ˜“å¯¹è±¡
        mock_trade = Mock()
        mock_trade.open_rate = 100.0
        mock_trade.leverage = 1.0
        mock_trade.is_short = False
        
        current_time = datetime.now()
        current_rate = 95.0
        current_profit = -0.05
        
        # æµ‹è¯•æ­¢æŸè®¡ç®—
        stoploss = optimized_strategy.custom_stoploss_optimized(
            'BTC/USDT', mock_trade, current_time, current_rate, current_profit
        )
        
        assert isinstance(stoploss, float), "æ­¢æŸå€¼ç±»å‹é”™è¯¯"
        assert -1.0 <= stoploss <= 0, f"æ­¢æŸå€¼è¶…å‡ºåˆç†èŒƒå›´: {stoploss}"
        
        logger.info(f"âœ… è‡ªå®šä¹‰æ­¢æŸæµ‹è¯•é€šè¿‡ - æ­¢æŸå€¼: {stoploss}")
    
    def test_performance_comparison(self, optimized_strategy, sample_data):
        """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
        logger.info("æµ‹è¯•æ€§èƒ½å¯¹æ¯”...")
        
        metadata = {'pair': 'BTC/USDT'}
        
        # æµ‹è¯•å¤šæ¬¡è°ƒç”¨çš„æ€§èƒ½
        times = []
        for i in range(5):
            start_time = time.time()
            result = optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
            elapsed_time = time.time() - start_time
            times.append(elapsed_time)
        
        # ç¬¬ä¸€æ¬¡åº”è¯¥è¾ƒæ…¢ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        # åç»­åº”è¯¥è¾ƒå¿«ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
        avg_time = sum(times[1:]) / len(times[1:])  # æ’é™¤ç¬¬ä¸€æ¬¡
        first_time = times[0]
        
        assert avg_time < first_time * 0.5, f"å¹³å‡æ€§èƒ½æœªæå‡: ç¬¬ä¸€æ¬¡{first_time:.3f}s, å¹³å‡{avg_time:.3f}s"
        
        logger.info(f"âœ… æ€§èƒ½å¯¹æ¯”æµ‹è¯•é€šè¿‡ - ç¬¬ä¸€æ¬¡: {first_time:.3f}s, å¹³å‡: {avg_time:.3f}s")
    
    def test_cache_statistics(self, optimized_strategy, sample_data):
        """æµ‹è¯•ç¼“å­˜ç»Ÿè®¡"""
        logger.info("æµ‹è¯•ç¼“å­˜ç»Ÿè®¡...")
        
        metadata = {'pair': 'BTC/USDT'}
        
        # å¤šæ¬¡è°ƒç”¨ä»¥ç”Ÿæˆç»Ÿè®¡
        for i in range(3):
            optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = optimized_strategy.get_performance_stats()
        
        assert 'cache_performance' in stats, "ç¼“å­˜ç»Ÿè®¡ç¼ºå¤±"
        assert 'hits' in stats['cache_performance'], "ç¼“å­˜å‘½ä¸­ç»Ÿè®¡ç¼ºå¤±"
        assert 'misses' in stats['cache_performance'], "ç¼“å­˜æœªå‘½ä¸­ç»Ÿè®¡ç¼ºå¤±"
        assert 'hit_rate' in stats['cache_performance'], "ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡ç¼ºå¤±"
        
        # éªŒè¯ç»Ÿè®¡å€¼åˆç†æ€§
        hit_rate = stats['cache_performance']['hit_rate']
        assert 0 <= hit_rate <= 1, f"ç¼“å­˜å‘½ä¸­ç‡å¼‚å¸¸: {hit_rate}"
        
        logger.info(f"âœ… ç¼“å­˜ç»Ÿè®¡æµ‹è¯•é€šè¿‡ - å‘½ä¸­ç‡: {hit_rate:.2%}")
    
    def test_memory_cleanup(self, optimized_strategy, sample_data):
        """æµ‹è¯•å†…å­˜æ¸…ç†"""
        logger.info("æµ‹è¯•å†…å­˜æ¸…ç†...")
        
        metadata = {'pair': 'BTC/USDT'}
        
        # å¤šæ¬¡è®¡ç®—ä»¥å¡«å……ç¼“å­˜
        for i in range(10):
            optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
        
        # è®°å½•æ¸…ç†å‰çŠ¶æ€
        stats_before = optimized_strategy.get_performance_stats()
        cache_size_before = stats_before['cache_performance']['cache_size']
        
        # æ‰§è¡Œå†…å­˜æ¸…ç†
        optimized_strategy.cleanup_memory()
        
        # è®°å½•æ¸…ç†åçŠ¶æ€
        stats_after = optimized_strategy.get_performance_stats()
        
        assert 'cache_performance' in stats_after, "æ¸…ç†åç»Ÿè®¡ç¼ºå¤±"
        
        logger.info(f"âœ… å†…å­˜æ¸…ç†æµ‹è¯•é€šè¿‡ - æ¸…ç†å‰ç¼“å­˜å¤§å°: {cache_size_before}")
    
    def test_error_handling(self, optimized_strategy, sample_data):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        logger.info("æµ‹è¯•é”™è¯¯å¤„ç†...")
        
        # æµ‹è¯•æ— æ•ˆå…ƒæ•°æ®
        invalid_metadata = None
        try:
            result = optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), invalid_metadata)
            # åº”è¯¥èƒ½å¤„ç†Noneå…ƒæ•°æ®
            assert result is not None, "åº”è¯¥èƒ½å¤„ç†æ— æ•ˆå…ƒæ•°æ®"
        except Exception as e:
            logger.warning(f"å¤„ç†æ— æ•ˆå…ƒæ•°æ®æ—¶å‡ºé”™: {e}")
        
        # æµ‹è¯•ç©ºæ•°æ®
        empty_data = pd.DataFrame()
        try:
            result = optimized_strategy.calculate_indicators_with_cache(empty_data, {'pair': 'BTC/USDT'})
            # åº”è¯¥èƒ½å¤„ç†ç©ºæ•°æ®
        except Exception as e:
            logger.warning(f"å¤„ç†ç©ºæ•°æ®æ—¶å‡ºé”™: {e}")
        
        logger.info("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")
    
    def test_signal_consistency(self, optimized_strategy, sample_data):
        """æµ‹è¯•ä¿¡å·ä¸€è‡´æ€§"""
        logger.info("æµ‹è¯•ä¿¡å·ä¸€è‡´æ€§...")
        
        metadata = {'pair': 'BTC/USDT'}
        
        # å¤šæ¬¡è®¡ç®—ç›¸åŒçš„ä¿¡å·
        results = []
        for i in range(3):
            dataframe = optimized_strategy.calculate_indicators_with_cache(sample_data.copy(), metadata)
            entry_df = optimized_strategy.populate_entry_trend_with_cache(dataframe.copy(), metadata)
            exit_df = optimized_strategy.populate_exit_trend_with_cache(dataframe.copy(), metadata)
            
            results.append({
                'entry': entry_df[['enter_long', 'enter_short']].copy(),
                'exit': exit_df[['exit_long', 'exit_short']].copy()
            })
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        for i in range(1, len(results)):
            pd.testing.assert_frame_equal(results[0]['entry'], results[i]['entry'])
            pd.testing.assert_frame_equal(results[0]['exit'], results[i]['exit'])
        
        logger.info("âœ… ä¿¡å·ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")

class TestIntegration:
    """é›†æˆæµ‹è¯•ç±»"""
    
    def test_complete_workflow(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹"""
        logger.info("æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹...")
        
        try:
            from NostalgiaForInfinityX6_CC_performance_only import PerformanceCache, MemoryOptimizedDataFrame
            
            # æµ‹è¯•å†…å­˜ä¼˜åŒ–
            test_data = pd.DataFrame({
                'open': np.random.randn(1000) + 100,
                'high': np.random.randn(1000) + 101,
                'low': np.random.randn(1000) + 99,
                'close': np.random.randn(1000) + 100,
                'volume': np.random.randint(1000, 10000, 1000)
            })
            
            opt_df = MemoryOptimizedDataFrame(test_data)
            memory_stats = opt_df.get_memory_saved()
            
            assert memory_stats['memory_saved_percent'] > 0, "å†…å­˜ä¼˜åŒ–æœªç”Ÿæ•ˆ"
            
            # æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ
            cache = PerformanceCache(max_size=100, ttl_seconds=60)
            cache.set('test_key', 'test_value')
            retrieved_value = cache.get('test_key')
            
            assert retrieved_value == 'test_value', "ç¼“å­˜ç³»ç»Ÿå·¥ä½œå¼‚å¸¸"
            
            logger.info("âœ… é›†æˆæµ‹è¯•é€šè¿‡")
            
        except ImportError as e:
            logger.warning(f"é›†æˆæµ‹è¯•è·³è¿‡ - æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            pytest.skip("é›†æˆæµ‹è¯•æ¨¡å—ä¸å¯ç”¨")

def run_performance_benchmark():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    logger.info("è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
    
    try:
        from NostalgiaForInfinityX6_CC_performance_only import create_performance_wrapper
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        np.random.seed(42)
        dates = pd.date_range(start='2023-01-01', periods=5000, freq='5min')
        test_data = pd.DataFrame({
            'open': 100 + np.random.randn(5000).cumsum() * 0.1,
            'high': 101 + np.random.randn(5000).cumsum() * 0.1,
            'low': 99 + np.random.randn(5000).cumsum() * 0.1,
            'close': 100 + np.random.randn(5000).cumsum() * 0.1,
            'volume': np.random.randint(1000, 10000, 5000),
            'date': dates
        })
        
        # æ¨¡æ‹ŸåŸå§‹ç­–ç•¥
        class MockOriginalStrategy:
            def __init__(self):
                self.stoploss = -0.50
            
            def populate_indicators(self, dataframe, metadata):
                for i in range(30):
                    dataframe[f'indicator_{i}'] = dataframe['close'].rolling(i+1).mean()
                return dataframe
            
            def populate_entry_trend(self, dataframe, metadata):
                dataframe['enter_long'] = (dataframe['close'] > dataframe['close'].rolling(20).mean()).astype(int)
                return dataframe
            
            def populate_exit_trend(self, dataframe, metadata):
                dataframe['exit_long'] = (dataframe['close'] < dataframe['close'].rolling(20).mean()).astype(int)
                return dataframe
        
        # æµ‹è¯•åŸå§‹ç­–ç•¥æ€§èƒ½
        original_strategy = MockOriginalStrategy()
        metadata = {'pair': 'BTC/USDT'}
        
        # åŸå§‹ç­–ç•¥æ‰§è¡Œæ—¶é—´
        start_time = time.time()
        for i in range(10):
            result = original_strategy.populate_indicators(test_data.copy(), metadata)
        original_time = time.time() - start_time
        
        # ä¼˜åŒ–ç­–ç•¥æ‰§è¡Œæ—¶é—´
        optimized_strategy = create_performance_wrapper(original_strategy)
        
        start_time = time.time()
        for i in range(10):
            result = optimized_strategy.calculate_indicators_with_cache(test_data.copy(), metadata)
        optimized_time = time.time() - start_time
        
        # è®¡ç®—æ€§èƒ½æå‡
        speedup = original_time / optimized_time if optimized_time > 0 else float('inf')
        
        logger.info(f"åŸºå‡†æµ‹è¯•ç»“æœ:")
        logger.info(f"åŸå§‹ç­–ç•¥æ‰§è¡Œæ—¶é—´: {original_time:.3f}s")
        logger.info(f"ä¼˜åŒ–ç­–ç•¥æ‰§è¡Œæ—¶é—´: {optimized_time:.3f}s")
        logger.info(f"æ€§èƒ½æå‡: {speedup:.2f}x")
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        stats = optimized_strategy.get_performance_stats()
        hit_rate = stats['cache_performance']['hit_rate']
        logger.info(f"ç¼“å­˜å‘½ä¸­ç‡: {hit_rate:.2%}")
        
        return {
            'original_time': original_time,
            'optimized_time': optimized_time,
            'speedup': speedup,
            'cache_hit_rate': hit_rate
        }
        
    except Exception as e:
        logger.error(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    print("ğŸ§ª è¿è¡Œç»¼åˆä¼˜åŒ–æµ‹è¯•å¥—ä»¶")
    print("=" * 50)
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark_results = run_performance_benchmark()
    
    if benchmark_results:
        print(f"\nğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"æ€§èƒ½æå‡: {benchmark_results['speedup']:.2f}x")
        print(f"ç¼“å­˜å‘½ä¸­ç‡: {benchmark_results['cache_hit_rate']:.2%}")
    
    print(f"\nğŸ§ª è¿è¡Œ pytest æµ‹è¯•...")
    
    # è¿è¡Œ pytest æµ‹è¯•
    pytest_args = [
        __file__,
        '-v',
        '--tb=short',
        '--log-cli-level=INFO'
    ]
    
    pytest.main(pytest_args)
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")