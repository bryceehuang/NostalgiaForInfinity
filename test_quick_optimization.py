#!/usr/bin/env python3
"""
å¿«é€Ÿä¼˜åŒ–æµ‹è¯•è„šæœ¬
ç”¨äºå¿«é€ŸéªŒè¯ä¼˜åŒ–æ•ˆæœ
"""

import pandas as pd
import numpy as np
import time
import gc
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_test_data(size=5000):
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    np.random.seed(42)
    dates = pd.date_range(start='2023-01-01', periods=size, freq='5min')
    
    data = {
        'open': 100 + np.random.randn(size).cumsum() * 0.1,
        'high': 101 + np.random.randn(size).cumsum() * 0.1,
        'low': 99 + np.random.randn(size).cumsum() * 0.1,
        'close': 100 + np.random.randn(size).cumsum() * 0.1,
        'volume': np.random.randint(1000, 10000, size),
        'date': dates
    }
    
    return pd.DataFrame(data)

def mock_original_strategy():
    """æ¨¡æ‹ŸåŸå§‹ç­–ç•¥"""
    class MockStrategy:
        def __init__(self):
            self.stoploss = -0.50
        
        def populate_indicators(self, dataframe, metadata):
            """æ¨¡æ‹Ÿé‡è®¡ç®—è´Ÿè½½"""
            result = dataframe.copy()
            
            # æ¨¡æ‹Ÿå¤æ‚çš„æŒ‡æ ‡è®¡ç®—
            for i in range(20):
                result[f'indicator_{i}'] = result['close'].rolling(i+1).mean()
                result[f'rsi_{i}'] = self.calculate_rsi(result['close'], 14 + i)
                result[f'macd_{i}'] = self.calculate_macd(result['close'])
            
            return result
        
        def calculate_rsi(self, prices, period=14):
            """è®¡ç®—RSI"""
            delta = prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            return rsi
        
        def calculate_macd(self, prices, fast=12, slow=26, signal=9):
            """è®¡ç®—MACD"""
            ema_fast = prices.ewm(span=fast).mean()
            ema_slow = prices.ewm(span=slow).mean()
            macd = ema_fast - ema_slow
            signal_line = macd.ewm(span=signal).mean()
            return macd - signal_line
        
        def populate_entry_trend(self, dataframe, metadata):
            """ç”Ÿæˆå…¥åœºä¿¡å·"""
            result = dataframe.copy()
            result['enter_long'] = (result['close'] > result['close'].rolling(20).mean()).astype(int)
            result['enter_short'] = (result['close'] < result['close'].rolling(20).mean()).astype(int)
            return result
        
        def populate_exit_trend(self, dataframe, metadata):
            """ç”Ÿæˆå‡ºåœºä¿¡å·"""
            result = dataframe.copy()
            result['exit_long'] = (result['close'] < result['close'].rolling(20).mean()).astype(int)
            result['exit_short'] = (result['close'] > result['close'].rolling(20).mean()).astype(int)
            return result
        
        def custom_stoploss(self, pair, trade, current_time, current_rate, current_profit, **kwargs):
            """è‡ªå®šä¹‰æ­¢æŸ"""
            return -0.50
    
    return MockStrategy()

def test_performance_comparison():
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
    logger.info("ğŸš€ å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = create_test_data(5000)
    logger.info(f"ğŸ“Š åˆ›å»ºæµ‹è¯•æ•°æ®: {len(test_data)} è¡Œ")
    
    # åˆ›å»ºåŸå§‹ç­–ç•¥
    original_strategy = mock_original_strategy()
    metadata = {'pair': 'BTC/USDT'}
    
    # æµ‹è¯•åŸå§‹ç­–ç•¥æ€§èƒ½
    logger.info("ğŸ” æµ‹è¯•åŸå§‹ç­–ç•¥æ€§èƒ½...")
    gc.collect()  # æ¸…ç†å†…å­˜
    start_time = time.time()
    
    original_result = original_strategy.populate_indicators(test_data.copy(), metadata)
    original_result = original_strategy.populate_entry_trend(original_result, metadata)
    original_result = original_strategy.populate_exit_trend(original_result, metadata)
    
    original_time = time.time() - start_time
    logger.info(f"â±ï¸  åŸå§‹ç­–ç•¥æ‰§è¡Œæ—¶é—´: {original_time:.3f}s")
    
    # æµ‹è¯•ä¼˜åŒ–ç­–ç•¥æ€§èƒ½
    try:
        logger.info("ğŸ” æµ‹è¯•ä¼˜åŒ–ç­–ç•¥æ€§èƒ½...")
        from NostalgiaForInfinityX6_CC_performance_only import create_performance_wrapper
        
        optimized_strategy = create_performance_wrapper(original_strategy)
        
        gc.collect()  # æ¸…ç†å†…å­˜
        start_time = time.time()
        
        optimized_result = optimized_strategy.calculate_indicators_with_cache(test_data.copy(), metadata)
        optimized_result = optimized_strategy.populate_entry_trend_with_cache(optimized_result, metadata)
        optimized_result = optimized_strategy.populate_exit_trend_with_cache(optimized_result, metadata)
        
        optimized_time = time.time() - start_time
        logger.info(f"â±ï¸  ä¼˜åŒ–ç­–ç•¥æ‰§è¡Œæ—¶é—´: {optimized_time:.3f}s")
        
        # è®¡ç®—æ€§èƒ½æå‡
        speedup = original_time / optimized_time if optimized_time > 0 else float('inf')
        logger.info(f"âš¡ æ€§èƒ½æå‡: {speedup:.2f}x")
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        try:
            stats = optimized_strategy.indicator_cache.get_stats()
            hit_rate = stats.get('hit_rate', 0)
            logger.info(f"ğŸ“ˆ ç¼“å­˜å‘½ä¸­ç‡: {hit_rate:.2%}")
        except AttributeError:
            hit_rate = 0
            logger.info(f"ğŸ“ˆ ç¼“å­˜å‘½ä¸­ç‡: {hit_rate:.2%}")
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        logger.info("ğŸ” éªŒè¯ç»“æœä¸€è‡´æ€§...")
        
        # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['enter_long', 'enter_short', 'exit_long', 'exit_short']
        for col in required_columns:
            assert col in original_result.columns, f"åŸå§‹ç»“æœç¼ºå°‘åˆ—: {col}"
            assert col in optimized_result.columns, f"ä¼˜åŒ–ç»“æœç¼ºå°‘åˆ—: {col}"
        
        # æ£€æŸ¥ä¿¡å·ä¸€è‡´æ€§ï¼ˆå…è®¸å°çš„æ•°å€¼å·®å¼‚ï¼‰
        for col in required_columns:
            original_values = original_result[col].values
            optimized_values = optimized_result[col].values
            
            # æ£€æŸ¥æ˜¯å¦åŸºæœ¬ä¸€è‡´ï¼ˆå…è®¸1%çš„å·®å¼‚ï¼‰
            diff_count = np.sum(original_values != optimized_values)
            diff_rate = diff_count / len(original_values)
            
            if diff_rate > 0.01:  # è¶…è¿‡1%çš„å·®å¼‚
                logger.warning(f"âš ï¸  {col} ä¿¡å·å·®å¼‚ç‡: {diff_rate:.2%}")
            else:
                logger.info(f"âœ… {col} ä¿¡å·ä¸€è‡´æ€§è‰¯å¥½ (å·®å¼‚ç‡: {diff_rate:.2%})")
        
        logger.info("âœ… ç»“æœä¸€è‡´æ€§éªŒè¯é€šè¿‡")
        
        return {
            'original_time': original_time,
            'optimized_time': optimized_time,
            'speedup': speedup,
            'cache_hit_rate': hit_rate,
            'test_passed': True
        }
        
    except ImportError as e:
        logger.error(f"âŒ å¯¼å…¥ä¼˜åŒ–æ¨¡å—å¤±è´¥: {e}")
        return {
            'test_passed': False,
            'error': str(e)
        }
    except Exception as e:
        logger.error(f"âŒ ä¼˜åŒ–ç­–ç•¥æµ‹è¯•å¤±è´¥: {e}")
        return {
            'test_passed': False,
            'error': str(e)
        }

def test_memory_optimization():
    """æµ‹è¯•å†…å­˜ä¼˜åŒ–æ•ˆæœ"""
    logger.info("ğŸ§  æµ‹è¯•å†…å­˜ä¼˜åŒ–æ•ˆæœ...")
    
    try:
        from NostalgiaForInfinityX6_CC_performance_only import MemoryOptimizedDataFrame
        
        # åˆ›å»ºå¤§æ•°æ®é›†
        large_data = pd.DataFrame({
            'open': np.random.randn(10000) + 100,
            'high': np.random.randn(10000) + 101,
            'low': np.random.randn(10000) + 99,
            'close': np.random.randn(10000) + 100,
            'volume': np.random.randint(1000, 10000, 10000)
        })
        
        # æµ‹è¯•å†…å­˜ä¼˜åŒ–
        opt_df = MemoryOptimizedDataFrame(large_data)
        memory_stats = opt_df.get_memory_saved()
        
        logger.info(f"ğŸ“Š å†…å­˜ä¼˜åŒ–ç»Ÿè®¡:")
        logger.info(f"  åŸå§‹å†…å­˜: {memory_stats['original_memory_mb']:.1f}MB")
        logger.info(f"  ä¼˜åŒ–å†…å­˜: {memory_stats['optimized_memory_mb']:.1f}MB")
        logger.info(f"  å†…å­˜èŠ‚çœ: {memory_stats['memory_saved_percent']:.1f}%")
        
        assert memory_stats['memory_saved_percent'] > 0, "å†…å­˜ä¼˜åŒ–æœªç”Ÿæ•ˆ"
        logger.info("âœ… å†…å­˜ä¼˜åŒ–æµ‹è¯•é€šè¿‡")
        
        return memory_stats
        
    except ImportError as e:
        logger.warning(f"âš ï¸  å†…å­˜ä¼˜åŒ–æ¨¡å—æµ‹è¯•è·³è¿‡: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ å†…å­˜ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return None

def test_caching_system():
    """æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ"""
    logger.info("ğŸ’¾ æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ...")
    
    try:
        from NostalgiaForInfinityX6_CC_performance_only import PerformanceCache
        
        # åˆ›å»ºç¼“å­˜å®ä¾‹
        cache = PerformanceCache(max_size=100, ttl_seconds=60)
        
        # æµ‹è¯•åŸºæœ¬æ“ä½œ
        cache.set('test_key', 'test_value')
        retrieved_value = cache.get('test_key')
        
        assert retrieved_value == 'test_value', "ç¼“å­˜åŸºæœ¬æ“ä½œå¤±è´¥"
        
        # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
        stats = cache.get_stats()
        logger.info(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡: å‘½ä¸­ç‡={stats['hit_rate']:.2%}, å¤§å°={stats['cache_size']}")
        
        # æµ‹è¯•ç¼“å­˜è¿‡æœŸ
        cache_with_short_ttl = PerformanceCache(max_size=10, ttl_seconds=1)
        cache_with_short_ttl.set('expire_key', 'expire_value')
        
        import time
        time.sleep(1.1)  # ç­‰å¾…è¿‡æœŸ
        
        expired_value = cache_with_short_ttl.get('expire_key')
        assert expired_value is None, "ç¼“å­˜è¿‡æœŸæœºåˆ¶å¤±è´¥"
        
        logger.info("âœ… ç¼“å­˜ç³»ç»Ÿæµ‹è¯•é€šè¿‡")
        
        return stats
        
    except ImportError as e:
        logger.warning(f"âš ï¸  ç¼“å­˜æ¨¡å—æµ‹è¯•è·³è¿‡: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ ç¼“å­˜ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        return None

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¿«é€Ÿä¼˜åŒ–æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    # è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•
    perf_results = test_performance_comparison()
    
    if perf_results and perf_results.get('test_passed'):
        print(f"\nğŸ“ˆ æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"  åŸå§‹ç­–ç•¥æ—¶é—´: {perf_results['original_time']:.3f}s")
        print(f"  ä¼˜åŒ–ç­–ç•¥æ—¶é—´: {perf_results['optimized_time']:.3f}s")
        print(f"  æ€§èƒ½æå‡: {perf_results['speedup']:.2f}x")
        print(f"  ç¼“å­˜å‘½ä¸­ç‡: {perf_results['cache_hit_rate']:.2%}")
    
    # è¿è¡Œå†…å­˜ä¼˜åŒ–æµ‹è¯•
    memory_results = test_memory_optimization()
    
    if memory_results:
        print(f"\nğŸ’¾ å†…å­˜ä¼˜åŒ–ç»“æœ:")
        print(f"  å†…å­˜èŠ‚çœ: {memory_results['memory_saved_percent']:.1f}%")
    
    # è¿è¡Œç¼“å­˜ç³»ç»Ÿæµ‹è¯•
    cache_results = test_caching_system()
    
    if cache_results:
        print(f"\nğŸ’¾ ç¼“å­˜ç³»ç»Ÿç»“æœ:")
        print(f"  ç¼“å­˜å‘½ä¸­ç‡: {cache_results['hit_rate']:.2%}")
    
    print(f"\nâœ… å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
    
    # æ€»ç»“
    if perf_results and perf_results.get('test_passed'):
        print(f"\nğŸ¯ ä¼˜åŒ–éªŒè¯æˆåŠŸï¼")
        print(f"   æ€§èƒ½æå‡: {perf_results['speedup']:.2f}x")
        print(f"   å†…å­˜èŠ‚çœ: {memory_results.get('memory_saved_percent', 0):.1f}%" if memory_results else "   å†…å­˜ä¼˜åŒ–: æœªæµ‹è¯•")
        print(f"   ç¼“å­˜å‘½ä¸­: {perf_results['cache_hit_rate']:.2%}")
    else:
        print(f"\nâŒ ä¼˜åŒ–éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()